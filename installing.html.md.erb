---
title: Installing and Configuring PKS
owner: PKS
---

<p class="note"><strong>Note</strong>: The PKS documentation is under development. This topic will continue to be updated and expanded to reflect the most current information.</p>

This topic describes how to install and configure Pivotal Container Service (PKS).

If you want to install PKS on vSphere with NSX-T integration, see [Installing and Configuring PKS with NSX-T Integration](installing-nsx-t.html).

##<a id='resources'></a> Resource Requirements

Installing PKS deploys the following two virtual machines (VMs):

<table>
<tr>
<th>VM</th>
<th>CPU</th>
<th>RAM</th>
<th>Ephemeral Disk</th>
<th>Persistent Disk</th>
</tr>
<td>Pivotal Container Service</td>
<td>1</td>
<td>4 GB</td>
<td>20 GB</td>
<td>n/a</td>
</tr>
</table>

Each Kubernetes cluster provisioned through PKS deploys the following VMs:

<table>
<tr>
<th>Number</th>
<th>VM</th>
<th>CPU</th>
<th>RAM</th>
<th>Ephemeral Disk</th>
<th>Persistent Disk</th>
</tr>
<td>1</td>
<td>etcd</td>
<td>1</td>
<td>1 GB</td>
<td>8 GB</td>
<td>2 GB</td>
</tr>
</tr>
<td>1</td>
<td>master</td>
<td>1</td>
<td>4 GB</td>
<td>8 GB</td>
<td>n/a</td>
</tr>
<tr>
<td>1</td>
<td>worker node</td>
<td>2</td>
<td>4 GB</td>
<td>8 GB</td>
<td>10 GB</td>
</tr>
</table>

##<a id='prereqs'></a> Prerequisites

Installing PKS requires the following:

* An external load balancer to access the PKS API
* An external load balancer to access each created cluster
* Ops Manager v2.0 configured with a [service network](https://docs.pivotal.io/pivotalcf/customizing/vsphere-config.html#create-networks) and [post-deploy scripts enabled](https://docs.pivotal.io/pivotalcf/customizing/vsphere-config.html#dir-config)
  <p class="note"><strong>Note</strong>: Configure your services subnet to use a DNS range from the internal Google network. Set this value on the <strong>Create Networks</strong> page in the Ops Manager Director tile.</p>
* [Kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/), the Kubernetes CLI, to access created clusters

##<a id='install'></a> Step 1: Install PKS

Perform the following steps to install PKS:

1. Download the product file from [Pivotal Network](https://network.pivotal.io).
1. Navigate to `YOUR-OPSMAN-FQDN` in a browser to log in to the Ops Manager Installation Dashboard.
1. From the Ops Manager Installation Dashboard, click **Import a Product** to upload the product file.
1. Under **Pivotal Container Service** in the left column, click the plus sign to add this product to your staging area.

##<a id='configure'></a> Step 2: Configure PKS

Click the orange **Pivotal Container Service** tile to start the configuration process.

###<a id='azs-networks'></a> Assign AZs and Networks

Perform the following steps:

1. Click **Assign AZs and Networks**.
1. Select an availability zone for your singleton jobs, and one or more availability zones to balance other jobs in. This is where PCF creates the PKS broker.
1. Under **Network**, select a subnet for the PKS broker. 
1. Under **Service Network**, select a subnet for the on-demand service instances created by the PKS broker.
1. Click **Save**.

###<a id='pks-api'></a> PKS API

Perform the following steps:

1. Click **PKS API**.
1. Under **Default Cluster Authorization Mode**, select an authentication mode for the Kubernetes clusters.
1. Under **Certificate**, provide your own certificate or have Ops Manager generate one.
1. Under **Generate RSA Certificate**, provide the domain names that you want your certificate to have. The domain names should contain 
the hostname you intend to use for accessing the PKS API service. 
1. Click **Save**.

###<a id='broker'></a> Broker

Perform the following steps:

1. Click **Broker**.
1. Under **Routing mode**, select a routing mode for the Kubernetes clusters deployed by PKS.
1. Under **AZ placement**, select an availability zone for the Kubernetes clusters deployed by PKS.
1. Click **Save**.

###<a id='plan'></a> Plan

Perform the following steps:

1. Click **Plan**.
1. Under **Plan description**, edit the description as needed. The plan description appears in the Services Marketplace, which developers can access by using either the Cloud Foundry Command Line Interface (cf CLI) or Apps Manager. 
1. Under **ETCD VM Type**, select the type of VM to use for the Kubernetes etcd nodes. 
	<p class="note"><strong>Note</strong>: This configuration is temporary until the master and etcd nodes are merged.</p>
1. Under **Master VM Type**, select the type of VM to use for Kubernetes master nodes.
1. Under **Worker VM Type**, select the type of VM to use for Kubernetes worker nodes.
1. Under **Worker Persistent Disk Type**, select the size of the persistent disk for the Kubernetes worker nodes.
1. Under **Worker Instances**, select the default number of Kubernetes worker nodes to provision for each cluster.
1. Click **Save**.

###<a id='iaas'></a> IaaS

Perform the following steps:

1. Click **IaaS**.
1. Under **Choose your IaaS**, select your IaaS.
1. Perform the steps specific to your IaaS.
	* For **vSphere**, ensure the values match those in the **vCenter Config** section of the **Ops Manager** tile:
		1. Enter your **vCenter Host**, such as `vcenter.cf-example.com`.
		1. Enter your **Datacenter Name**, such as `cf-example-dc`.
		1. Enter your **Cluster Name**, such as `cf-example-cluster`.
		1. Enter your **Datastore Name**, such as `cf-example-ds`.
		1. For **VM Folder**, enter the name of a VM and Template Folder in vCenter.
	* For **GCP**, ensure the values match those in the **Google Config** section of the **Ops Manager** tile:
	  1. Enter your **GCP Project Id**.
	  1. Enter your **GCP Network**, which is the VPC network name for your Ops Manager environment.
1. Click **Save**.

###<a id='networking'></a> Networking

Perform the following steps:

1. Click **Networking**.
1. Under **Network**, select the Container Network Interface to use.
	* For **Flannel**, no additional fields are required.
	* For **NSX-T**, see [Installing and Configuring PKS with NSX-T Integration](installing-nsx-t.html).
1. Click **Save**.

###<a id='resource-config'></a> (Optional) Resource Config

To modify the resource usage of PKS, click **Resource Config** and edit the **PKS on-demand broker** job.

###<a id='stemcell'></a> (Optional) Stemcell

To edit the stemcell configuration, click **Stemcell**. Click **Import Stemcell** to import a new stemcell. 

##<a id='apply-changes'></a> Step 3: Apply Changes

After configuring the tile, return to the Ops Manager Installation Dashboard and click **Apply Changes** to deploy the tile.

##<a id='post-deployment-steps'></a> Step 4: Post-Deployment Steps (GCP Only)

If you are deploying on Google Cloud Platform (GCP), you must create a service account and update the [cloud config](http://bosh.io/docs/cloud-config.html) after deploying the tile.

In order for Kubernetes to create load balancers and attach persistent disks to pods, you must create a service account with sufficient permissions. Then you must update the cloud config for all `vm_types` to include a `cloud_properties` value for `service_account`. 

<p class="note"><strong>Note</strong>: You must update the cloud config each time you redeploy PKS by clicking <strong>Apply Changes</strong> in Ops Manager.</p>

Perform the following steps:

1. Navigate to the **IAM & admin > Service accounts** section of the GCP Console.
1. Click **Create Service Account**.
1. Enter a name for the service account, and add the following roles:
  * `roles/iam.serviceAccountActor` (**Project > Service Account Actor**)
  * `roles/compute.instanceAdmin`  (**Compute Engine > Compute Instance Admin**)
  * `roles/compute.securityAdmin` (**Compute Engine > Compute Security Admin**)
  * `roles/compute.networkAdmin` (**Compute Engine > Compute Network Admin**)
  * `roles/compute.storageAdmin` (**Compute Engine > Compute Storage Admin**)
  * `roles/compute.viewer` (**Compute Engine > Compute Viewer**)
	<p class="note"><strong>Note</strong>: See the <code>kubo-deployment</code> GitHub <a href="https://github.com/cloudfoundry-incubator/kubo-deployment/blob/master/docs/user-guide/platforms/gcp/kubo-infrastructure.tf#L61-L110">repository</a> for more information about the required roles.</p>
1. Click **Furnish a new private key** and select **JSON**.
1. Click **Create**.
1. Set the name of the GCP service account as an environment variable. For example:
	<pre class="terminal">$ GCP\_SERVICE\_ACCOUNT="example-acct<span>@</span>project.iam.gserviceaccount.com"</pre>
1. Use the BOSH CLI v2 to export your cloud config as a YAML file, specifying the name of your environment:
	<pre class="terminal">$ bosh -e my-env cloud-config > cloud-config.yml</pre>
1. Create an environment variable with your VM types. You must have [Ruby](https://www.ruby-lang.org/en/downloads/) and [jq](https://stedolan.github.io/jq/) installed. Enter the following command:
	<pre class="terminal">$ VM\_TYPES=$(cat cloud-config.yml | ruby -ryaml -rjson -e 'puts JSON.pretty_generate(YAML.load(ARGF))' | jq -r '.vm\_types[].name')</pre>
1. Create a blank environment variable with the following command:
	<pre class="terminal">$ echo "" > UPDATE\_SERVICE\_ACCOUNT</pre>
1. Enter the following Bash script on the command line:

	```
	for vm_type in $VM_TYPES
	do
	  echo "- type: replace" >> UPDATE_SERVICE_ACCOUNT
	  echo "  path: /vm_types/name=${vm_type}/cloud_properties/service_account?" >> UPDATE_SERVICE_ACCOUNT
	  echo "  value: $GCP_SERVICE_ACCOUNT" >> UPDATE_SERVICE_ACCOUNT
	done
	```
1. Use the BOSH CLI v2 to update the cloud config. For example:
	<pre class="terminal">$ bosh --non-interactive update-cloud-config \ 
	cloud-config.yml --ops-file UPDATE\_SERVICE\_ACCOUNT</pre>
   Your PKS installation is now ready to use.

##<a id='retrieve-pks-api'></a> Step 5: Retrieve PKS API Endpoint

You must share the PKS API endpoint to allow your organization to use the API to create, update, and delete clusters.

When an operator creates a cluster, they provide an IP address for the Kubernetes master host, then point the load balancer to the newly created cluster.
If you use a load balancer as a service (LBaaS) tool, your LBaaS may manage cluster creation and configuration.

See [Using PKS](using.html#create-cluster) for more information.

Perform the following steps to retrieve the PKS API endpoint:

1. Navigate to the Ops Manager Installation Dashboard. 
1. Click the PKS tile.
1. Click the **Status** tab and locate the IP address of the PKS API endpoint. This is the endpoint that developers use to create and manage clusters.

##<a id='loadbalancer-pks-api'></a> Step 6: Configure External Load Balancer

Configure your external load balancer to resolve to the domain name used in the certificate you provided during the [PKS API](#pks-api) section of the tile configuration. Your external load balancer will forward traffic to the PKS API endpoint.




