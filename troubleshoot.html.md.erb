ne#encoding: utf-8
---
title: Diagnosing and Troubleshooting PKS
owner: Ops Manager
---

This topic is intended to provide assistance when diagnosing and troubleshooting issues installing or using Pivotal Container Service (PKS).

##<a id='diagnose'></a>Diagnostic Tools

###<a id='pks-cli'></a>Verify PKS CLI Version

The Pivotal Container Service (PKS) CLI interacts with the your PKS deployment through the PKS API endpoint. You create, manage, and delete Kubernetes clusters on your PKS deployment by entering commands in the PKS CLI. The PKS CLI is under active development and commands may change between versions.

Run `pks --version` to determine the version of PKS CLI installed locally. For example:

<pre class="terminal">
$ pks --version
PKS CLI version: 0.7.1-build.6
</pre>

###<a id='bosh-pks-map'></a>View Logs Files

Log files contain error messages and other information you can use to diagnose issues with your PKS deployment. Follow the steps below to access PKS log files.

1. Gather credential and IP address information for your BOSH Director, SSH into the Ops Manager VM, and use the BOSH CLI v2 to log in to the BOSH Director from the Ops Manager VM.
For more information, see [Advanced Troubleshooting with the BOSH CLI](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html).

1. After logging in to the BOSH Director, identify the name of your PKS deployment. For example:
  <pre class="terminal">$ bosh -e pks deployments</pre>
  Your PKS deployment name begins with `pivotal-container-service` and includes a BOSH-generated hash.

1. On a command line, run `bosh -e pks -d YOUR-DEPLOYMENT-NAME vms` to list the virtual machines (VMs) in your PKS deployment. For example:
  <pre class="terminal">$ bosh -e pks -d pivotal-container-service-aa1234567bc8de9f0a1c vms</pre>

1. Run `bosh -e pks -d YOUR-DEPLOYMENT-NAME ssh VM-NAME/GUID` to ssh into a PKS VM. 
    * To access logs on the master VM, replace `VM-NAME/GUID` with the name of the PKS master VM, and `GUID` with the GUID of the master VM. 
    * To access logs on a worker VM, replace `VM-NAME/GUID` with the name of a PKS worker VM, and `GUID` with the GUID of the same worker VM. 

1. Run `sudo su` to act as super user on the PKS VM.

1. Navigate to `/vars/vcap/sys/log` on the PKS VM:
  <pre class="terminal">
  $ cd /var/vcap/sys/log
  </pre>

1. Examine the following file:
  * On the PKS master VM, examine the `kubernetes-api` log file.
  * On a PKS worker VM, examine the `kubelet` log file.

## <a id="issues"></a>Troubleshooting 

### <a id="timeouts"></a>Cannot Access Add-On Features or Functions 

**Symptom**

You cannot access a feature or function provided by a Kubernetes add-on.

Examples include the following:  

- You cannot access the [Kubernetes Dashboard](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/) in a browser or using the kubectl command-line tool.
- [Heapster](https://github.com/kubernetes/heapster) does not start.
- Pods cannot resolve DNS names, and error messages report the service `kube-dns` is invalid. If `kube-dns` is not deployed, the cluster typically fails to start. 

**Explanation**

The Kubernetes features and functions listed above are provided by the following PKS add-ons: 

* **Kubernetes Dashboard** `kubernetes-dashboard`
* **Heapster**: `heapster`
* **DNS Resolution**: `kube-dns`

To enable these add-ons, Ops Manager must run scripts after deploying PKS. You must configure Ops Manager to automatically run these post-deploy scripts.

**Solution**

Perform the following steps to configure Ops Manager to run post-deploy scripts to deploy the missing add-ons to your cluster.

1. Navigate to `https://YOUR-OPS-MANAGER-FQDN/` in a browser to log in to the Ops Manager Installation Dashboard.

1. Click the Ops Manager v2.0 tile.

1. Select **Director Config**.

1. Select **Enable Post Deploy Scripts**.
  <p class="note"><strong>Note</strong>: This setting enables post-deploy scripts for all tiles in your Ops Manager installation.</p>

1. Click **Save**.

1. Click the **Installation Dashboard** link to return to the Installation Dashboard.

1. Click **Apply Changes**.

1. After Ops Manager finishes applying changes, enter `pks delete-cluster` on the command line to delete the cluster. For more information, see the [Delete Cluster](using.html#delete-cluster) section of _Using PKS_.

1. On the command line, enter `pks create-cluster` to recreate the cluster. For more information, see the [Create Cluster](using.html#create-cluster) section of the _Using PKS_.

<hr>

###<a id='bosh-pks-map'></a>Error: Failed Jobs

**Symptom**

In stdout or log files, you see an error message referencing `post-start scripts failed` or `Failed Jobs`.

**Explanation**

After deploying PKS, Ops Manager runs scripts to start a number of jobs. You must configure Ops Manager to automatically run these post-deploy scripts.

**Solution**

Perform the following steps to configure Ops Manager to run post-deploy scripts. 

1. Navigate to `https://YOUR-OPS-MANAGER-FQDN/` in a browser to log in to the Ops Manager Installation Dashboard.

1. Click the Ops Manager v2.0 tile.

1. Select **Director Config**.

1. Select **Enable Post Deploy Scripts**.
  <p class="note"><strong>Note</strong>: This setting enables post-deploy scripts for all tiles in your Ops Manager installation.</p>

1. Click **Save**.

1. Click the **Installation Dashboard** link to return to the Installation Dashboard.

1. Click **Apply Changes**.

1. After Ops Manager finishes applying changes, enter `pks delete-cluster` on the command line to delete the cluster. For more information, see the [Delete Cluster](using.html#delete-cluster) section of _Using PKS_.

1. On the command line, enter `pks create-cluster` to recreate the cluster. For more information, see the [Create Cluster](using.html#create-cluster) section of the _Using PKS_.

<hr>

###<a id='no-such-host'></a>Error: No Such Host

**Symptom**

In stdout or log files, you see an error message that includes `lookup vm-WORKER-NODE-GUID on IP-ADDRESS: no such host`.

**Explanation**

This error occurs on GCP when the Ops Manager Director tile uses 8.8.8.8 as the DNS server.
When this IP range is in use, the master node cannot locate the route to the worker nodes.

**Solution**

Use the Google internal DNS range, 169.254.169.254, as the DNS server.
