---
title: PKS Release Notes v1.0.2
owner: PKS
---

**Release Date**: TBD

<p class="note warning"><strong>WARNING</strong>: See <a href="#stemcell">Volume Unmount Failure After Stemcell Upgrade</a> for important information about upgrading to PKS v1.0.2.</p>

## <a id='bug-fixes'></a>Bug Fixes

### <a id='general-bug-fixes'></a>General

* **[Bug Fix]** Worker nodes are drained before they stop in order to minimize workload downtime during a rolling upgrade.
* **[Security Fix]** UAA credentials and vCenter passwords no longer appear in [BOSH logs](1.0.0.html#syslog-security).
* **[Bug Fix]** BOSH DNS no longer causes worker nodes to fail after a manual restart.
* **[Bug Fix]** Addresses upgrade issues in constrained environments.
* **[Bug Fix]** Removes additional whitespace in the Kubernetes Controller Manager certificate.
* **[Bug Fix]** Drain user given additional permissions to remove replication controller-owned pods.
* **[Bug Fix]** Updates to unmount Docker overlay volumes that caused BOSH unmount failures.
* Updates Kubernetes to v1.9.5.
* Updates Golang to v1.9.4.

### <a id='vsphere-bug-fixes'></a>vSphere

* **[Bug Fix]** vSphere NSX-T integration now works with BOSH [stemcell v3468.25](1.0.0.html#stemcell-incompatible) and later.
* **[Bug Fix]** For vSphere with NSX-T, the pod logical switch port (LSP) is updated when you recreate the VM that hosts the pod. See [StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) in the Kubernetes documentation and the [known issue](#statefulset) section below for more information.
* **[Bug Fix]** Added support for [special characters](1.0.0.html#special) `#`, `&`, `;`, `"`, `'`, `^`, `\`, space (` `), and `%` in vCenter passwords in the Kubernetes Cloud Provider tile configuration page.
* **[Bug Fix]** Drain script now deletes nodes to fix a vSphere issue where node names changed between 1.9.2 and 1.9.5.

## <a id='versions'></a>Component Versions

PKS v1.0.2 includes or supports the following component versions:

<table border="1" class="nice">
  <tbody>
    <tr>
    <th>Product Component</th>
    <th>Version Supported</th>
    <th>Notes</th>
   </tr>
   <tr>
   <td>vSphere</td>
   <td>6.5 and 6.5 U1 - Editions
    <ul><li>vSphere Enterprise Plus Edition</li></ul>
    <ul><li>vSphere with Operations Management Enterprise Plus</li></ul></td>
   <td>vSphere versions supported for Pivotal Container Service (PKS)</td>
   </tr>
   <tr>
   <td>VMware Harbor Registry</td>
   <td>1.4.1</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   <tr>
   <td>NSX-T</td>
   <td>2.1 Advanced Edition</td>
   <td>Available from VMware</td>
   </tr>
   <tr>
   <td>Pivotal Cloud Foundry Operations Manager (Ops Manager)</td>
   <td>2.0.X</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   <tr>
   <td>Stemcell</td>
   <td>3468.21</td>
   <td>Separate download available from Pivotal Network</td>
   </tr>
   <tr>
   <td>Kubernetes</td>
   <td>1.9.5*</td>
   <td>Packaged in the PKS Tile (CFCR)</td>
   </tr>
   <tr>
   <td>CFCR (Kubo)</td>
   <td>0.13</td>
   <td>Packaged in the PKS Tile</td>
   </tr>
   <tr>
   <td>NCP</td>
   <td>2.1.2</td>
   <td>Packaged in the PKS Tile</td>
   </tr>
   <tr>
   <td>PKS CLI</td>
   <td>1.0.2-build.4</td>
   <td>Separate download available from the PKS section of Pivotal Network</td>
   </tr>
   <tr>
   <td>Kubernetes CLI</td>
   <td>1.9.5</td>
   <td>Separate download available from the PKS section of Pivotal Network</td>
   </tr>
   </tbody>
   <tfoot>
   <tr>
    <td colspan="3"><em>* Components marked with an asterisk have been patched to resolve security vulnerabilities or fix component behavior.</em></td>
   </tr>
  </tfoot>
</table>

## <a id='known-issues'></a>Known Issues

This section includes known issues with PKS v1.0.2 and corresponding workarounds.

### <a id='general-known-issues'></a>General

#### <a id='stemcell'></a>Volume Unmount Failure After Stemcell Upgrade

During an upgrade to PKS v1.0.2, BOSH can fail to unmount the `/var/vcap/store` volume on worker nodes.
This is due to an issue with the Docker BOSH release installed by the PKS v1.0.0 tile.
In this version of the BOSH release, Docker occasionally fails to unmount all overlays when stopping a node.

This issue occurs because VMs are recreated when you upgrade the stemcell.
To avoid this issue, Pivotal recommends performing the following procedure before upgrading to PKS v1.0.2:

1. Download the [docker_ctl](../1.0.2/stemcell/docker_ctl) script.
1. Download the [docker\_ctl\_update.sh](../1.0.2/stemcell/docker_ctl_update.sh) script.
1. From a terminal with BOSH access, execute the `docker_ctl_update.sh` script.

The `docker_ctl_update.sh` script replaces the `docker_ctl` script on all worker nodes that have Docker deployed.
The script contains the fix to correctly unmount Docker overlays.

After running the script, you can perform the PKS tile upgrade by clicking **Apply Changes** in Ops Manager.

See [Upgrade PKS](../upgrade-pks.html) for more information about upgrading PKS.

#### <a id="automatic-rolling"></a>Stemcell Updates Cause Automatic VM Rolling

Enabling the **Upgrade all clusters** errand allows automatic rolling for VMs in your deployment.
Pivotal recommends enabling this errand to ensure that all deployed cluster VMs are patched.

When you enable the **Upgrade all clusters** errand, the following actions can cause downtime:

* Updating the PKS tile with a new stemcell triggers the rolling of each VM in each cluster.
* Updating other tiles in your deployment with new stemcells causes the rolling of the PKS tile.

#### <a id="upgrade-fail"></a>Upgrade Errand Fails with Failed Deployments
The **Upgrade all clusters** errand fails if any deployments are in a failed state.

To work around this issue, [delete the failed cluster](../delete-cluster.html) using the PKS CLI or [redeploy the failed cluster](../manage-deployments-bosh.html) with the BOSH CLI to ensure the cluster is in a successful state.

### <a id='vsphere-known-issues'></a>vSphere

#### <a id='cold-migration'></a>Pods Lose Network Connectivity After VM Cold Migration

When a Kubernetes cluster worker VM goes through cold migration in vSphere, newly provisioned pods lose network connectivity.

This issue can occur under the following conditions:

* When the VM is powered off and is subject to cold migration, and the VM moves to a different ESXi host
* When the VM is powering on and is subject to Distributed Resource Scheduler (DRS) before the powerup completes
* When the vNIC of the VM is detached and reattached

To work around this issue, delete the worker VM.
BOSH recreates the worker VM and restores network connectivity.â€¨

#### <a id='statefulset'></a>StatefulSets Pod Failure After Recreating a VM

When using vSphere with NSX-T integration, if you recreate a node that hosts a StatefulSets pod, the pod can get stuck in a `ContainerCreating` state.
The pod emits a warning event with a `FailedCreatePodSandBox` reason.
This issue affects StatefulSets pods created before PKS v1.0.2.

A fix for this bug is included in PKS v1.0.2, but the fix applies only to StatefulSets created using PKS v1.0.2 or later.
After upgrading PKS to v1.0.2, manually deleting and recreating all preexisting StatefulSets pods is recommended, even if they are in a running state.

To get all StatefulSets pods, run the following command on every Kubernetes cluster using the Kubernetes admin user permissions:

<pre>$ kubectl get pods -l "statefulset.kubernetes.io/pod-name" \
-o wide --all-namespaces</pre>

For each result, delete the pod by running the following command:

<pre>$ kubectl delete pod POD-NAME -n POD-NAMESPACE</pre>

You do not need to manually recreate the deleted pods.
Kubernetes detects a StatefulSet with missing pods and automatically recreates the pods.

#### <a id="detach"></a>[Kubernetes Bug] Upgrading a Cluster Affects Persistent Workload Uptime

During an upgrade to v1.0.2 on vSphere, persistent storage volumes do not reattach to pods until all worker nodes have been upgraded, which results in workload downtime until the entire cluster is upgraded.

This issue occurs when you deploy a pod with persistent storage attached, drain the node, and then immediately delete the node VM.

The expected behavior is for persistent disks to reattach to the upgraded VMs after the pod is restored.
However, a Kubernetes bug prevents the disk from reattaching.
PKS v1.0.2 works around this bug by attaching the volumes after all workers are upgraded.

For more information, see the [Kubernetes issue on GitHub](https://github.com/kubernetes/kubernetes/issues/61707).

In rare cases, pods with persistent volumes can stay in `ContainerCreating` state.
If you see the error `FailedMount Unable to mount volumes for pod POD-NAME`, perform the following steps:

1. Find the problem node by running `kubectl describe pod POD-NAME`.
2. Prevent scheduling on the node that runs the pod by running `kubectl cordon NODE-NAME`.
3. Delete pod by running `kubectl delete pod POD-NAME`.
4. Wait for pod to be rescheduled and enter `Running` state. This may take several minutes.
5. Resume scheduling on the node that runs the pod by running `kubectl uncordon NODE-NAME`.

### <a id="nsx-t-password"></a>Kubernetes Cluster Creation Fails if NSX-T Manager Password Begins with @
 
If NSX-T is selected as a **Container Network Type** in PKS and if the NSX-T Manager password has an `@` character at the beginning, Kubernetes cluster creation fails.
To fix this problem, reset your NSX-T Manager password so that it does not begin with an `@` character.
After resetting your NSX-T Manager password, reconfigure your NSX-T Manager credentials in the PKS tile with the updated password.

#### <a id="special"></a>Special Characters
In PKS v1.0.2, `!` cannot be used in vCenter passwords.
