---
title: Using PKS
owner: PKS
---

<strong><%= modified_date %></strong>

<p class="note"><strong>Note</strong>: The PKS documentation is under development. This topic will continue to be updated and expanded to reflect the most current information.</p>

This topic describes how to use Pivotal Container Service (PKS).

Please send any feedback you have to [pks-feedback@pivotal.io](mailto:pks-feedback@pivotal.io).

After an operator has [installed](installing.html) PKS, developers can use the PKS Command Line Interface (PKS CLI) or `curl` commands to do the following:

* [Create](#create-cluster) a Kubernetes cluster
* [Retrieve the credentials and configuration](#get-credentials) for a Kubernetes cluster so that they can deploy application workloads to the cluster with the `kubectl`, the Kubernetes CLI
* [View](#view-cluster-list) the list of running Kubernetes clusters
* [View](#view-cluster) details about a Kubernetes cluster
* [View](#view-cluster-plans) the list of available plans for deploying a Kubernetes cluster
* [Resize](#resize) the number of worker nodes in a Kubernetes cluster
* [Access](#access-dashboard) the Dashboard for a Kubernetes cluster
* [Deploy](#deploy-access-workloads) and access basic workloads
* [Delete](#delete-cluster) a Kubernetes cluster

<p class="note warning"><strong>WARNING</strong>: The PKS CLI is under active development and commands may change. 
To ensure you have installed the latest version, we recommend that you re-install the PKS CLI before you use it. 
To install the PKS CLI, see <a href="installing-pks-cli.html">Installing the PKS CLI</a>.</p>

<p class="note"><strong>Note</strong>: Because PKS does not currently support the Kubernetes Service Catalog or the GCP Service Broker, binding clusters to Kubernetes services is not supported.</p>

##<a id='prereqs'></a> Prerequisites

The procedures in this topic have the following prerequisites:

* You must have a Pivotal Cloud Foundry (PCF) deployment with Ops Manager v2.0 or later and PKS installed.

* You must have the [PKS CLI](installing-pks-cli.html) installed.
  <p class="note warning"><strong>WARNING</strong>: The PKS CLI is under active development and commands may change. To ensure you have installed the latest version, we recommend that you re-install the PKS CLI before you use it. To install the PKS CLI, see <a href="installing-pks-cli.html">Installing the PKS CLI</a>.</p>

* You must have `kubectl`, the Kubernetes CLI, installed. To download and install `kubectl`, see the [Install and Set Up kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-via-curl) topic in the Kubernetes documentation. For more information about using `kubectl`, see the [kubectl documentation](https://kubernetes.io/docs/user-guide/kubectl-overview/).

* You must have an external load balancer configured to forward traffic to the PKS API endpoint. For more information, see the [Configure External Load Balancer](installing.html#loadbalancer-pks-api) section of <em>Installing and Configuring PKS</em>.

* You must have your PKS API endpoint and your PKS API credentials. To retrieve these values, the operator performs the following steps:
  1. Navigate to the **Pivotal Container Service** tile in the Ops Manager Installation Dashboard.
  1. Click the **Status** tab.
  1. Retrieve the PKS API endpoint under **IPs**, and the PKS API credentials under **PKS Basic Auth**.
  <p class="note"><strong>Note</strong> If your PKS installation is integrated with NSX-T, developers should use the DNAT IP address assigned in the <a href="installing-nsx-t.html#apply-changes">Apply Changes and Retrieve the PKS Endpoint</a> section of <em>Installing and Configuring PKS with NSX-T Integration</em>.</p>

##<a id='create-cluster'></a> Create Cluster

You can create a Kubernetes cluster using the PKS CLI or with `curl` commands.

### Create a Cluster Using the PKS CLI

Follow the steps below to create a Kubernetes cluster using the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

2. Run the following command to create a cluster:
  <br>
  ```
  pks create-cluster CLUSTER-NAME --external-hostname HOSTNAME --plan PLAN-NAME [--num-nodes WORKER-NODES]
  ```
  <br>
  Replace the placeholder values in the command as follows:
  * `CLUSTER-NAME` is a unique name for your cluster.
  * `HOSTNAME` is an external hostname for accessing your Kubernetes API, such as a load balancer. If your PKS installation is integrated with NSX-T, this may be the NAT IP from the `ip-pool-vips` NSX IP pool. For more information, see [Enable NAT Access](installing-nsx-t.html#nsxt-master-nat) in <em>Installing and Configuring PKS with NSX-T Integration</em>.
  * `PLAN-NAME` is the name of the plan you want to use to create the cluster.
  * `WORKER-NODES` is the number of worker nodes for the cluster. The maximum value is 50. This flag is optional.
  <br><br>
  For example:
  <pre class="terminal">$ pks create-cluster my-cluster --external-hostname 10.0.0.1 --plan large --num-nodes 3</pre>

1. Track the cluster creation process by running `bosh tasks`. For example:
  1. Gather credential and IP address information for your BOSH Director, SSH into the Ops Manager VM, and use the BOSH CLI v2 to log in to the BOSH Director from the Ops Manager VM.
  For more information, see [Advanced Troubleshooting with the BOSH CLI](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html).
  1. After logging in to the BOSH Director, identify the names of the VMs you want to retrieve logs from by listing all VMs in your deployment. For example:
    <pre class="terminal">$ bosh -e pks -d my-dep vms</pre>
  1. Run `bosh tasks` to watch the cluster creation task. For example:
    <pre class="terminal">$ bosh -e pks -d my-dep tasks</pre>
    See the [BOSH documentation](https://bosh.io/docs/director-tasks.html#active) for more information.

See [Managing PKS](managing.html) for information about checking cluster health and viewing cluster logs.

### Create a Cluster with curl Commands

Follow the steps below to create a Kubernetes cluster with `curl` commands. 

1. Choose a unique name for your cluster. On the command line, set it as an environment variable named `CLUSTER_NAME`. For example:
  <pre class="terminal">$ export CLUSTER_NAME="my-cluster"</pre>

1. Retrieve the IP address of your external load balancer and set it as an environment variable named `KUBERNETES_SERVICE_HOST`. For example:
  <pre class="terminal">$ export KUBERNETES&#95;SERVICE_HOST="192.0.2.0"</pre>

1. Choose either attribute-based access control (ABAC) or role-based access control (RBAC) for your authorization mode. Set an environment variable named `AUTHORIZATION_MODE` to `abac`for ABAC or `rbac` for RBAC. For example:
  <pre class="terminal">$ export AUTHORIZATION_MODE="rbac"</pre>
  For more information about authorization modes, see the [Kubernetes documentation](https://kubernetes.io/docs/admin/authorization/#authorization-modules).

1. Set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API_ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API_CREDS="username:password"</pre>

1. Set your plan name as an environment variable named `PLAN_NAME`. For example:
  <pre class="terminal">$ export PLAN_NAME="Example Cluster Plan"</pre>

1. (Optional) By default, the Kubernetes API listens on port 8443. To configure a different port, set the `kubernetes_master_port` parameter to your desired port.

1. Decide if you want to specify the number of worker nodes in your `curl` command, or when use the number of worker nodes you configured the **Plan** section of the PKS tile. For more information about configuring the **Plan** section of the PKS tile, see the [Plan](installing.html#plan) section of <em>Installing and Configuring PKS</em>.

  1. If you want to specify the number of worker nodes in your `curl` command,  set the environment variable named `KUBERNETES_WORKER_INSTANCES` to your desired number of Kubernetes worker nodes. This value must be between 1 and 50, inclusive. For example:
  <pre class="terminal">$ export KUBERNETES&#95;WORKER&#95;INSTANCES=3</pre>
  Run the following command to create the cluster: 
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X POST \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8' \
    -d "{\"name\": \"$CLUSTER&#95;NAME\",\"plan\": \"$PLAN&#95;NAME\",\"parameters\": \
    {\"kubernetes&#95;master&#95;host\": \"$KUBERNETES&#95;SERVICE&#95;HOST\", \
    \"kubernetes&#95;worker&#95;instances\": $KUBERNETES&#95;WORKER&#95;INSTANCES, \
    \"authorization&#95;mode\": \"$AUTHORIZATION&#95;MODE\" }}" \
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/
  </pre>
  1. If you want to use the number of worker nodes you specified when configuring the **Plan** section of the PKS tile, run the following command to create the cluster: 
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X POST \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8' \
    -d "{\"name\": \"$CLUSTER&#95;NAME\",\"plan\": \"$PLAN&#95;NAME\",\"parameters\": \
    {\"kubernetes&#95;master&#95;host\": \"$KUBERNETES&#95;SERVICE&#95;HOST\", \
    \"authorization&#95;mode\": \"$AUTHORIZATION&#95;MODE\" }}" \
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/
  </pre>

1. Ensure your operator has configured the external load balancer to point to the master virtual machine of the newly created cluster.

1. Track the cluster creation process by running `bosh tasks`. For example:
  1. Gather credential and IP address information for your BOSH Director, SSH into the Ops Manager VM, and use the BOSH CLI v2 to log in to the BOSH Director from the Ops Manager VM.
  For more information, see [Advanced Troubleshooting with the BOSH CLI](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html).
  1. After logging in to the BOSH Director, identify the names of the VMs you want to retrieve logs from by listing all VMs in your deployment. For example:
    <pre class="terminal">$ bosh -e pks -d my-dep vms</pre>
  1. Run `bosh tasks` to watch the cluster creation task. For example:
    <pre class="terminal">$ bosh -e pks -d my-dep tasks</pre>
    See the [BOSH documentation](https://bosh.io/docs/director-tasks.html#active) for more information.

See [Managing PKS](managing.html) for information about checking cluster health and viewing cluster logs.

##<a id='get-credentials'></a> Retrieve Cluster Credentials and Configuration

You can retrieve Kubernetes cluster credentials and configuration using the PKS CLI or with `curl` commands.

### Retrieve Credentials and Configuration Using the PKS CLI

Follow the steps below to retrieve the cluster credentials and configuration using the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

1. Run the following command to retrieve the cluster credentials and configuration:
  <br>
  ```
  pks get-credentials CLUSTER-NAME
  ```
  <br>  
  Replace `CLUSTER-NAME` with the unique name for your cluster.
  For example:
  <pre class="terminal">$ pks get-credentials my-cluster</pre>

You can use the `pks get-credentials` command to perform the following actions:

  - Fetch the cluster's `kubeconfig`
  - Add the cluster's `kubeconfig` to the existing `kubeconfig`
  - Create a new `kubeconfig`, if none exists
  - Switch the context to the `CLUSTER-NAME` provided

The `kubeconfig` file path works the same way as `kubectl`.
If you do not set the file path, the default path is `$HOME/.kube/config`.
Use the `KUBECONFIG` environment variable to change the `kubeconfig` file path.

You can use the credentials and the `kubeconfig` to deploy application workloads to your cluster with `kubectl`. For more information about accessing your cluster, see the [Kubernetes documentation](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/).

### Retrieve Credentials and Configuration with curl Commands

Follow the steps below to retrieve the cluster credentials and configuration with `curl` commands. 

1. On the command line, set the name of the cluster as an environment variable named `CLUSTER_NAME`. For example:
  <pre class="terminal">$ export CLUSTER_NAME="my-cluster"</pre>

1. Set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Run the following command to retrieve the cluster credentials and configuration and export them as an environment variable named `CREDENTIALS`:
  <pre class='code'>
  export CREDENTIALS="$(curl -k -u $PKS&#95;API&#95;CREDS -s -X POST \
    --header 'Content-Type: application/json' \
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/$CLUSTER&#95;NAME/binds)"
  </pre>

1. If the command completes successfully, it saves a JSON response with the cluster credentials and the cluster configuration. This file is called the `kubeconfig`. Run `echo $CREDENTIALS` to view the contents of the `kubeconfig`.
  Example:
  <pre class="terminal">
  $ echo $CREDENTIALS
    {
      "apiVersion": "v1",
      "clusters": [
        {
          "cluster": {
            "certificate-authority-data": "some&#95;data",
            "server": "http<span>s:/</span>/server"
          },
          "name": "kubo-cluster"
        }
      ],
      "contexts": [
        {
          "context": {
            "cluster": "kubo-cluster",
            "user": "some&#95;user"
          },
          "name": "kubo-cluster"
        }
      ],
      "current-context": "kubo-cluster",
      "kind": "Config",
      "preferences": {},
      "users": [
        {
          "name": "some&#95;name",
          "user": {
            "token": "some&#95;token"
          }
        }
      ]
    }
  </pre>

1. Run the following command to set the `kubeconfig` in `$HOME/.kube/config`:
  <pre class="terminal">$ echo $CREDENTIALS > "${HOME}/.kube/config"</pre>
  <p class="note"><strong>Note</strong>: This command overwrites any existing file at <code>$HOME/.kube/config</code>.</p>

You can use the credentials and the `kubeconfig` to deploy application workloads to your cluster with `kubectl`. For more information about accessing your cluster, see the [Kubernetes documentation](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/).

##<a id='view-cluster-list'></a> View Cluster List

You can view the list of deployed Kubernetes cluster using the PKS CLI or with `curl` commands.

### View Cluster List Using the PKS CLI

Follow the steps below to view the list of deployed Kubernetes cluster with the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

1. Run the following command to view the list of deployed clusters, including cluster names and status:
  <br>
  ```
   pks list-clusters
  ```

### View Cluster List with curl Command 

Follow the steps below to view the list of deployed Kubernetes cluster with `curl` commands.

1. On the command line, set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Run the following command to view the list of deployed clusters, including cluster names and status:
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X GET \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8'\
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters
  </pre>

##<a id='view-cluster'></a> View Cluster Details

You can view the details of an individual cluster using the PKS CLI or with `curl` commands.

### View Cluster Details Using the PKS CLI

Follow the steps below to view the details of an individual cluster using the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

1. Run the following command to view the details of an individual cluster:
  <br>
  ```
  pks show-cluster CLUSTER-NAME
  ```
  <br>
  Replace `CLUSTER-NAME` with the unique name for your cluster.
  For example:
  <pre class="terminal">$ pks show-cluster my-cluster</pre>

### View Cluster Details with curl Commands

Follow the steps below to view the details of an individual cluster with `curl` commands.

1. On the command line, set the name of the cluster as an environment variable named `CLUSTER_NAME`. For example:
  <pre class="terminal">$ export CLUSTER_NAME="my-cluster"</pre>

1. Set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Run the following command to view the details of an individual cluster:
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X GET \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8'\
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/$CLUSTER&#95;NAME/
  </pre>

##<a id='view-cluster-plans'></a> View Cluster Plans

You can view information about the available plans for deploying a cluster using the PKS CLI or with `curl` commands.

### View Cluster Plans Using the PKS CLI

Follow the steps below to view information about the available plans for deploying a cluster using the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

1. Run the following command to view information about the available plans for deploying a cluster:
  <pre class="terminal">$ pks list-plans</pre>
  The response lists details about the available plans, including plan names and descriptions:
  <pre class="terminal">
  Name     ID  Description
  default      Default plan for K8s cluster
  </pre>

### View Cluster Plans with curl Commands

Follow the steps below to view information about the available plans for deploying a cluster with `curl` commands.

1. On the command line, set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Run the command below to view information about the available plans for deploying a cluster. The response lists details about the available plans, including plan names and descriptions.
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X GET \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8'\
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/plans
  </pre>

##<a id='dynamic-volumes'></a>Using Dynamic Persistent Volumes

When using PKS, you can choose to pre-provision persistent storage or create on-demand persistent storage volumes.
Refer to the [Kubernetes documentation](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) for more information about storage management.

Perform the steps in this section to define a `PersistentVolumeClaim` that you can apply to newly-created pods.

1. Download the `StorageClass` spec for your cloud provider.
  * **GCP**: <pre class="terminal">$ wget https&#58;//raw.githubusercontent.com/cloudfoundry-incubator/kubo-ci/master/specs/storage-class-gcp.yml</pre>
  * **vSphere**: <pre class="terminal">$ wget https&#58;//raw.githubusercontent.com/cloudfoundry-incubator/kubo-ci/master/specs/storage-class-vsphere.yml</pre>

1. Apply the spec by running `kubectl create -f STORAGE-CLASS-SPEC.yml`.
Replace `STORAGE-CLASS-SPEC` with the name of the file you downloaded in the previous step.
For example:
<pre class="terminal">$ kubectl create -f storage-class-gcp.yml</pre>

1. Run the following command to download the example `PersistentVolumeClaim`:
<pre class="terminal">$ wget https&#58;//raw.githubusercontent.com/cloudfoundry-incubator/kubo-ci/master/specs/persistent-volume-claim.yml
</pre>

1. Run the following command to apply the `PersistentVolumeClaim`:
<pre class="terminal">
$ kubectl create -f persistent-volume-claim.yml
</pre>
  * To confirm you applied the `PersistentVolumeClaim`, run the following command:
  <pre class="terminal">
  $ kubectl get pvc -o wide
  </pre>

1. To use the dynamic persistent volume, create a pod that uses the `PersistentVolumeClaim`.
See the [pv-guestbook.yml configuration file](https://github.com/cloudfoundry-incubator/kubo-ci/blob/master/specs/pv-guestbook.yml) as an example.

##<a id='scale-clusters'></a> Scale Existing Clusters

You can scale up existing clusters using the PKS CLI or with `curl` commands.

<p class="note"><strong>Note</strong>: You cannot scale the number of worker nodes down. You can only scale the number of worker nodes up.</p>

### Scale Up an Existing Cluster Using the PKS CLI

Follow the steps below to scale up an existing cluster using the PKS CLI.

1. On the command line, run the following command to log in:
  <br>
  ```
  pks login -a PKS_API -u USERNAME -p PASSWORD
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.
1. Run the following command below to scale up your cluster. You cannot scale the number of worker nodes down. 
  <p class="note"><strong>Note</strong>: This command may roll additional VMs in the cluster, affecting workloads if the worker nodes are at capacity. This issue will be resolved in a future release of PKS.</p>
  <br>
  ```
  pks resize CLUSTER-NAME --num-nodes WORKER-NODES
  ```
  <br>  
  Replace the placeholder values in the command as follows:
  * `CLUSTER-NAME` is the name of your cluster.
  * `WORKER-NODES` is the number of worker nodes for the cluster. The maximum number of worker nodes is 50.
  For example:
  <pre class="terminal">$ pks resize my-cluster --num-nodes 5</pre>

### Scale Up an Existing Cluster with curl Commands

Follow the steps below to scale up an existing cluster with `curl` commands.

1. On the command line, set the name of the cluster as an environment variable named `CLUSTER_NAME`. For example:
  <pre class="terminal">$ export CLUSTER&#95;NAME="my-cluster"</pre>

1. Set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Set the environment variable named `KUBERNETES_WORKER_INSTANCES` to your desired number of Kubernetes worker nodes. This value must be between 1 and 50, inclusive. For example:
  <pre class="terminal">$ export KUBERNETES&#95;WORKER&#95;INSTANCES=3</pre>

1. Run the following command below to scale up your cluster. You cannot scale the number of worker nodes down. 
  <pre class='code'>
  curl -k -u $PKS&#95;API&#95;CREDS -s -X PATCH \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/json;charset=UTF-8'\
    -d '{"kubernetes&#95;worker&#95;instances": $KUBERNETES&#95;WORKER&#95;INSTANCES }'\
    https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/$CLUSTER&#95;NAME/
  </pre>
  <p class="note"><strong>Note</strong>: This command provides no on-screen response.</p>

##<a id='access-dashboard'></a> Access the Dashboard

_Dashboard_ is a web-based Kubernetes user interface. You can use Dashboard to deploy containerized applications to a Kubernetes cluster, troubleshoot containerized applications, and manage the cluster and its resources. Dashboard also provides information about the state of Kubernetes resources in the cluster.

You must have `kubectl` credentials to access Dashboard. This requirement prevents unauthorized admin access to the Kubernetes cluster through a browser. 

Follow the steps below to access the Dashboard for a Kubernetes cluster.

1. As a PKS operator or developer, you may already have access to `kubectl` credentials. If you do not, follow the instruction in the 
[Retrieve Cluster Credentials and Configuration](#get-credentials) section of this topic to retrieve these credentials.

1. After retrieving `kubectl` credentials, run `kubectl proxy` on a command line. Do not exit or close the terminal.

1. In a web browser, browse to `http://localhost:8001/ui` to access the Dashboard.

##<a id='deploy-access-workloads'></a> Deploy and Access Basic Workloads

You can deploy and access workloads in a number of ways. This PKS release focuses on `routing_mode: external` and does not include a bundled load balancing component. Select an option based on your PKS deployment:

* [No Load Balancer Abstraction Configured / vSphere without NSX-T](#without-lb)

* [Load Balancer Abstraction Configured / GCP or vSphere with NSX-T](#with-lb)

* [External Load Balancer](#external-lb)

###<a id='without-lb'></a> No Load Balancer Abstraction Configured / vSphere without NSX-T

If you use vSphere without NSX-T or configuring a load balancer abstraction, follow the steps below to deploy and access basic workloads.

1. Expose the workload using a Service with `type: NodePort`.

1. Download the spec for a basic NGINX app from the [pivotal-cf-experimental/kubo-ci](https://github.com/pivotal-cf-experimental/kubo-ci/blob/master/specs/nginx.yml) GitHub repository.

1. Run `kubectl create -f nginx.yml` to deploy the basic NGINX app. This command creates three pods (replicas) that span three worker nodes.

1. Retrieve the IP address for a worker node with a running NGINX pod.
  <p class='note'><strong>Note</strong>: If you deployed more than four worker
  nodes, some worker nodes may not contain a running NGINX pod. Select a worker
  node that contains a running NGINX pod.</p>
  <br>
  You can retrieve the IP address for a worker node with a running NGINX pod in
  one of the following ways:
  * On the command line, run `kubectl get nodes`. Select a node name, then locate the node name in the vCenter or GCP Console to find the IP address.
  * On the Ops Manager command line, run `bosh vms` to find the IP address.

1. On the command line, run `kubectl get svc nginx`. Find the node port number in the `3XXXX` range.

1. On the command line of a server with network connectivity and visibility to the IP address of the worker node, run `curl http://NODE-IP:NODE-PORT` to access the app. Replace `NODE-IP` with the IP address of the worker node, and `NODE-PORT` with the node port number.

###<a id='with-lb'></a> Load Balancer Abstraction Configured / GCP or vSphere with NSX-T

If you use GCP or vSphere with NSX-T, follow the steps below to deploy and access basic workloads.

<p class='note'><strong>Note</strong>: This approach creates a dedicated load balancer for each workload. This may be an inefficient use of resources in clusters with many apps.</p>

1. Expose the workload using a Service with `type: LoadBalancer`.

1. Download the spec for a basic NGINX app from the [cloudfoundry-incubator/kubo-ci](https://github.com/cloudfoundry-incubator/kubo-ci/blob/master/specs/nginx-lb.yml) GitHub repository.

1. Run `kubectl create -f nginx.yml` to deploy the basic NGINX app. This command creates three pods (replicas) that span three worker nodes.

1. Wait until the GCP CloudProvider interacts with GCP to create a dedicated load balancer and connects it the the worker nodes on a specific port.

1. Run `kubectl get svc nginx` and retrieve the load balancer IP address and port number.

1. On the command line of a server with network connectivity and visibility to the IP address of the worker node, run `curl http://EXTERNAL-IP:PORT` to access the app. Replace `EXTERNAL-IP:PORT` with the IP address of the load balancer, and `PORT` with the port number.

###<a id='external-lb'></a> External Load Balancer

All deployments can use an external load balancer. If you want to use an external load balancer, follow the steps below to deploy and access basic workloads.

1. Expose every workload and app using a Service with `type: NodePort`.

1. Map each node port exposed in the worker nodes that you need to an external port in your external load balancer. The process to map these ports depends on your load balancer. See your external load balancer documentation for more information.

1. For each app, run `curl http://LOAD-BALANCER-IP:EXTERNAL-PORT`. Replace `LOAD-BALANCER-IP` with the IP address of your external load balancer and `EXTERNAL-PORT` with the external port number.

##<a id='delete-cluster'></a> Delete a Cluster

You can delete a cluster using the PKS CLI or with `curl` commands.

### Delete a Cluster Using the PKS CLI

Follow the steps below to delete a cluster using the PKS CLI.

1. On the command line, run `pks login -a PKS_API -u USERNAME -p PASSWORD` to log in. Replace the placeholder values in the command as follows:
  * `PKS_API` is your PKS API hostname. For example, `10.85.102.12`. The PKS CLI uses port 9021 by default.
  * `USERNAME` is your PKS API username.
  * `PASSWORD` is your PKS API password.

1. Run `pks delete-cluster CLUSTER-NAME` to delete a cluster. Replace `CLUSTER-NAME` with the unique name for your cluster.
For example:
  <pre class="terminal">$ pks delete-cluster my-cluster</pre>

### Delete a Cluster Using curl Commands

Follow the steps below to delete a cluster using `curl` commands.

1. On the command line, set your PKS API endpoint as an environment variable named `PKS_API_ENDPOINT`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;ENDPOINT="pks.example.com"</pre>

1. Set your PKS API credentials as an environment variable named `PKS_API_CREDS`. For example:
  <pre class="terminal">$ export PKS&#95;API&#95;CREDS="username:password"</pre>

1. Set the name of the cluster you want to delete as an environment variable named `CLUSTER_NAME`. For example:
  <pre class="terminal">$ export CLUSTER&#95;NAME="my-cluster"</pre>

1. Run the following command to delete the cluster:
  <pre class="code">
  curl -k -u $PKS&#95;API&#95;CREDS -s -X DELETE \
  --header 'Content-Type: application/json' \
  --header 'Accept: application/json;charset=UTF-8' \
  https://$PKS&#95;API&#95;ENDPOINT:9021/v1/clusters/$CLUSTER#95;NAME/
  </pre>


